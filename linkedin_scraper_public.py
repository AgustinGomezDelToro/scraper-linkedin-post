# -*- coding: utf-8 -*-
"""LinkedIn_Scraper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xFmzIChGfL7YShHsR9uFAKZNvhdKeXrw
"""

#required installs (i.e. pip3 install in terminal): pandas, selenium, bs4, and possibly chromedriver(it may come with selenium)
#Download Chromedriver from: https://chromedriver.chromium.org/downloads
#To see what version to install: Go to chrome --> on top right click three dot icon --> help --> about Google Chrome
#Move the chrome driver to (/usr/local/bin) -- open finder -> Command+Shift+G -> search /usr/local/bin -> move from downloads

from selenium import webdriver
from bs4 import BeautifulSoup as bs
import time
import pandas as pd
import re as re


#accessing Chromedriver
browser = webdriver.Chrome('chromedriver')


#Replace with you username and password
username = "linkedin_username"
password = "linkedin password"

#Open login page
browser.get('https://www.linkedin.com/login?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin')


#Enter login info:
elementID = browser.find_element_by_id('username')
elementID.send_keys(username)

elementID = browser.find_element_by_id('password')
elementID.send_keys(password)
elementID.submit()


#Go to company webpage. Change page as needed
browser.get('https://www.linkedin.com/company/lor%C3%A9al/')


#Simulate scrolling to capture all posts
SCROLL_PAUSE_TIME = 1.5

# Get scroll height
last_height = browser.execute_script("return document.body.scrollHeight")

while True:
    # Scroll down to bottom
    browser.execute_script("window.scrollTo(0, document.body.scrollHeight);")

    # Wait to load page
    time.sleep(SCROLL_PAUSE_TIME)

    # Calculate new scroll height and compare with last scroll height
    new_height = browser.execute_script("return document.body.scrollHeight")
    if new_height == last_height:
        break
    last_height = new_height


    
#Check out page source code
company_page = browser.page_source   



# #Import exception check for message popups (not needed atm)
# from selenium.common.exceptions import NoSuchElementException
# try:
#     if browser.find_element_by_class_name('msg-overlay-list-bubble--is-minimized') is not None:
#         pass
# except NoSuchElementException:
#     try:
#         if browser.find_element_by_class_name('msg-overlay-bubble-header') is not None:
#             browser.find_element_by_class_name('msg-overlay-bubble-header').click()
#     except NoSuchElementException:
#         pass


#Use Beautiful Soup to get access tags
linkedin_soup = bs(company_page.encode("utf-8"), "html")
linkedin_soup.prettify()

#Find the post blocks
containers = linkedin_soup.findAll("div",{"class":"occludable-update ember-view"})
container = containers[0].find("div","feed-shared-update-v2__description-wrapper ember-view")



# Lists that we will iterate to
post_dates = []
post_texts = []
post_likes = []
post_comments = []
video_views = []


#Looping through the posts and appending them to the lists
for container in containers:
    posted_container = container.findAll("div",{"class": "display-flex feed-shared-actor display-flex feed-shared-actor--with-control-menu ember-view"})
    posted_date = posted_container[0].find("span",{"class": "feed-shared-actor__sub-description t-12 t-normal t-black--light"})
    box_container = container.findAll("div",{"class": "feed-shared-update-v2__description-wrapper ember-view"})
    new_box = box_container[0].find("span",{"dir":"ltr"})
    engagement_container = container.findAll("ul", class_="social-details-social-counts ember-view")
    new_likes = engagement_container[0].find("span", {"class": "v-align-middle social-details-social-counts__reactions-count"})
    new_comments = engagement_container[0].find("li", {"class": "social-details-social-counts__comments social-details-social-counts__item"})

    #Getting Video Views. (The folling three lines prevents class name overlap)
    view_container2 = set(container.findAll("li", {'class':["social-details-social-counts__item","social-details-social-counts__reactions social-details-social-counts__item"]}))
    view_container1 = set(container.findAll("li", {'class':["social-details-social-counts__reactions","social-details-social-counts__comments social-details-social-counts__item"]}))
    result = view_container2 - view_container1
    
    #Upacking the set into list
    view_container = []
    for i in result:
        view_container += i
    
    
    #Adding post views, likes, and comment values to lists if they exists
    try:
        video_views.append(view_container[1].text.strip().replace(' Views',''))
    
    except:
        video_views.append('')
    
    
    try:
        post_likes.append(new_likes.text.strip())
    except:
        post_likes.append(0)
        pass

    
    try:
        post_comments.append(new_comments.text.strip())                           
    except:                                                           
        post_comments.append(0)
        pass
    
    #Adding post date and text to list
    post_dates.append(posted_date.text.strip())
    post_texts.append(new_box.text.strip())


    
#Cleaning the dates
cleaned_dates = []
for i in post_dates:
    d = str(i[0:3]).replace('\n\n', '').replace('â€¢','').replace(' ', '')
    cleaned_dates += [d]


#Stripping non-numeric values
comment_count = []
for i in post_comments:
    s = str(i).replace('Comment','').replace('s','').replace(' ','')
    comment_count += [s]


    
#Constructing Pandas Dataframe
data = {
    "Date Posted": cleaned_dates,
    "Post Text": post_texts,
    "Post Likes": post_likes,
    "Post Comments": comment_count,
    "Video Views": video_views
}

df = pd.DataFrame(data)


#Exporting csv to program folder
df.to_csv("loreal_linkedin.csv", encoding='utf-8', index=False)