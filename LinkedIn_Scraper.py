{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinkedIn_Scraper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christophe-garon/LinkedIn-Page-Scraper/blob/main/LinkedIn_Scraper.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "rtZFckDN4CC_",
        "outputId": "9afcfd2e-a268-468a-dfad-062ebe6c7007"
      },
      "source": [
        "#required installs (i.e. pip3 install in terminal): pandas, selenium, bs4, and possibly chromedriver(it may come with selenium)\n",
        "#Download Chromedriver from: https://chromedriver.chromium.org/downloads\n",
        "#To see what version to install: Go to chrome --> on top right click three dot icon --> help --> about Google Chrome\n",
        "#Move the chrome driver to (/usr/local/bin) -- open finder -> Command+Shift+G -> search /usr/local/bin -> move from downloads\n",
        "\n",
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import time\n",
        "import pandas as pd\n",
        "import re as re\n",
        "\n",
        "\n",
        "#accessing Chromedriver\n",
        "browser = webdriver.Chrome('chromedriver')\n",
        "\n",
        "\n",
        "#Replace with you username and password\n",
        "username = \"linkedin_username\"\n",
        "password = \"linkedin password\"\n",
        "\n",
        "#Open login page\n",
        "browser.get('https://www.linkedin.com/login?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin')\n",
        "\n",
        "\n",
        "#Enter login info:\n",
        "elementID = browser.find_element_by_id('username')\n",
        "elementID.send_keys(username)\n",
        "\n",
        "elementID = browser.find_element_by_id('password')\n",
        "elementID.send_keys(password)\n",
        "elementID.submit()\n",
        "\n",
        "\n",
        "#Go to company webpage. Change page as needed\n",
        "browser.get('https://www.linkedin.com/company/lor%C3%A9al/')\n",
        "\n",
        "\n",
        "#Simulate scrolling to capture all posts\n",
        "SCROLL_PAUSE_TIME = 1.5\n",
        "\n",
        "# Get scroll height\n",
        "last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "while True:\n",
        "    # Scroll down to bottom\n",
        "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "\n",
        "    # Wait to load page\n",
        "    time.sleep(SCROLL_PAUSE_TIME)\n",
        "\n",
        "    # Calculate new scroll height and compare with last scroll height\n",
        "    new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
        "    if new_height == last_height:\n",
        "        break\n",
        "    last_height = new_height\n",
        "\n",
        "\n",
        "    \n",
        "#Check out page source code\n",
        "company_page = browser.page_source   \n",
        "\n",
        "\n",
        "\n",
        "# #Import exception check for message popups (not needed atm)\n",
        "# from selenium.common.exceptions import NoSuchElementException\n",
        "# try:\n",
        "#     if browser.find_element_by_class_name('msg-overlay-list-bubble--is-minimized') is not None:\n",
        "#         pass\n",
        "# except NoSuchElementException:\n",
        "#     try:\n",
        "#         if browser.find_element_by_class_name('msg-overlay-bubble-header') is not None:\n",
        "#             browser.find_element_by_class_name('msg-overlay-bubble-header').click()\n",
        "#     except NoSuchElementException:\n",
        "#         pass\n",
        "\n",
        "\n",
        "#Use Beautiful Soup to get access tags\n",
        "linkedin_soup = bs(company_page.encode(\"utf-8\"), \"html\")\n",
        "linkedin_soup.prettify()\n",
        "\n",
        "#Find the post blocks\n",
        "containers = linkedin_soup.findAll(\"div\",{\"class\":\"occludable-update ember-view\"})\n",
        "container = containers[0].find(\"div\",\"feed-shared-update-v2__description-wrapper ember-view\")\n",
        "\n",
        "\n",
        "\n",
        "# Lists that we will iterate to\n",
        "post_dates = []\n",
        "post_texts = []\n",
        "post_likes = []\n",
        "post_comments = []\n",
        "video_views = []\n",
        "\n",
        "\n",
        "#Looping through the posts and appending them to the lists\n",
        "for container in containers:\n",
        "    posted_container = container.findAll(\"div\",{\"class\": \"display-flex feed-shared-actor display-flex feed-shared-actor--with-control-menu ember-view\"})\n",
        "    posted_date = posted_container[0].find(\"span\",{\"class\": \"feed-shared-actor__sub-description t-12 t-normal t-black--light\"})\n",
        "    box_container = container.findAll(\"div\",{\"class\": \"feed-shared-update-v2__description-wrapper ember-view\"})\n",
        "    new_box = box_container[0].find(\"span\",{\"dir\":\"ltr\"})\n",
        "    engagement_container = container.findAll(\"ul\", class_=\"social-details-social-counts ember-view\")\n",
        "    new_likes = engagement_container[0].find(\"span\", {\"class\": \"v-align-middle social-details-social-counts__reactions-count\"})\n",
        "    new_comments = engagement_container[0].find(\"li\", {\"class\": \"social-details-social-counts__comments social-details-social-counts__item\"})\n",
        "\n",
        "    #Getting Video Views. (The folling three lines prevents class name overlap)\n",
        "    view_container2 = set(container.findAll(\"li\", {'class':[\"social-details-social-counts__item\",\"social-details-social-counts__reactions social-details-social-counts__item\"]}))\n",
        "    view_container1 = set(container.findAll(\"li\", {'class':[\"social-details-social-counts__reactions\",\"social-details-social-counts__comments social-details-social-counts__item\"]}))\n",
        "    result = view_container2 - view_container1\n",
        "    \n",
        "    #Upacking the set into list\n",
        "    view_container = []\n",
        "    for i in result:\n",
        "        view_container += i\n",
        "    \n",
        "    \n",
        "    #Adding post views, likes, and comment values to lists if they exists\n",
        "    try:\n",
        "        video_views.append(view_container[1].text.strip().replace(' Views',''))\n",
        "    \n",
        "    except:\n",
        "        video_views.append('')\n",
        "    \n",
        "    \n",
        "    try:\n",
        "        post_likes.append(new_likes.text.strip())\n",
        "    except:\n",
        "        post_likes.append(0)\n",
        "        pass\n",
        "\n",
        "    \n",
        "    try:\n",
        "        post_comments.append(new_comments.text.strip())                           \n",
        "    except:                                                           \n",
        "        post_comments.append(0)\n",
        "        pass\n",
        "    \n",
        "    #Adding post date and text to list\n",
        "    post_dates.append(posted_date.text.strip())\n",
        "    post_texts.append(new_box.text.strip())\n",
        "\n",
        "\n",
        "    \n",
        "#Cleaning the dates\n",
        "cleaned_dates = []\n",
        "for i in post_dates:\n",
        "    d = str(i[0:3]).replace('\\n\\n', '').replace('â€¢','').replace(' ', '')\n",
        "    cleaned_dates += [d]\n",
        "\n",
        "\n",
        "#Stripping non-numeric values\n",
        "comment_count = []\n",
        "for i in post_comments:\n",
        "    s = str(i).replace('Comment','').replace('s','').replace(' ','')\n",
        "    comment_count += [s]\n",
        "\n",
        "\n",
        "    \n",
        "#Constructing Pandas Dataframe\n",
        "data = {\n",
        "    \"Date Posted\": cleaned_dates,\n",
        "    \"Post Text\": post_texts,\n",
        "    \"Post Likes\": post_likes,\n",
        "    \"Post Comments\": comment_count,\n",
        "    \"Video Views\": video_views\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "#Exporting csv to program folder\n",
        "df.to_csv(\"loreal_linkedin.csv\", encoding='utf-8', index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom selenium import webdriver\\nfrom bs4 import BeautifulSoup as bs\\nimport time\\nimport pandas as pd\\nimport re as re\\n\\n\\n#accessing Chromedriver\\nbrowser = webdriver.Chrome(\\'chromedriver\\')\\n\\n\\n#Replace with you username and password\\nusername = \"linkedin_username\"\\npassword = \"linkedin password\"\\n\\n#Open login page\\nbrowser.get(\\'https://www.linkedin.com/login?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin\\')\\n\\n#Enter login info:\\nelementID = browser.find_element_by_id(\\'username\\')\\nelementID.send_keys(username)\\n\\nelementID = browser.find_element_by_id(\\'password\\')\\nelementID.send_keys(password)\\n#Note: replace the keys \"username\" and \"password\" with your LinkedIn login info\\nelementID.submit()\\n\\n\\n#Go to company webpage\\nbrowser.get(\\'https://www.linkedin.com/company/lor%C3%A9al/\\')\\n\\n\\n#Simulate scrolling to capture all posts\\nSCROLL_PAUSE_TIME = 1.5\\n\\n# Get scroll height\\nlast_height = browser.execute_script(\"return document.body.scrollHeight\")\\n\\nwhile True:\\n    # Scroll down to bottom\\n    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\\n\\n    # Wait to load page\\n    time.sleep(SCROLL_PAUSE_TIME)\\n\\n    # Calculate new scroll height and compare with last scroll height\\n    new_height = browser.execute_script(\"return document.body.scrollHeight\")\\n    if new_height == last_height:\\n        break\\n    last_height = new_height\\n\\n\\n#Check out page source code\\ncompany_page = browser.page_source   \\n\\n\\n\\n# #Import exception check for message popups (not needed atm)\\n# from selenium.common.exceptions import NoSuchElementException\\n# try:\\n#     if browser.find_element_by_class_name(\\'msg-overlay-list-bubble--is-minimized\\') is not None:\\n#         pass\\n# except NoSuchElementException:\\n#     try:\\n#         if browser.find_element_by_class_name(\\'msg-overlay-bubble-header\\') is not None:\\n#             browser.find_element_by_class_name(\\'msg-overlay-bubble-header\\').click()\\n#     except NoSuchElementException:\\n#         pass\\n\\n\\n#Use Beautiful Soup to get access tags\\nlinkedin_soup = bs(company_page.encode(\"utf-8\"), \"html\")\\nlinkedin_soup.prettify()\\n\\n#Find the post blocks\\ncontainers = linkedin_soup.findAll(\"div\",{\"class\":\"occludable-update ember-view\"})\\ncontainer = containers[0].find(\"div\",\"feed-shared-update-v2__description-wrapper ember-view\")\\n\\n\\n\\n# Lists that we will iterate to\\npost_dates = []\\npost_texts = []\\npost_likes = []\\npost_comments = []\\n\\n\\n#Looping through the posts and appending them to the lists\\nfor container in containers:\\n    posted_container = container.findAll(\"div\",{\"class\": \"display-flex feed-shared-actor display-flex feed-shared-actor--with-control-menu ember-view\"})\\n    posted_date = posted_container[0].find(\"span\",{\"class\": \"feed-shared-actor__sub-description t-12 t-normal t-black--light\"})\\n    box_container = container.findAll(\"div\",{\"class\": \"feed-shared-update-v2__description-wrapper ember-view\"})\\n    new_box = box_container[0].find(\"span\",{\"dir\":\"ltr\"})\\n    engagement_container = container.findAll(\"ul\", class_=\"social-details-social-counts ember-view\")\\n    new_likes = engagement_container[0].find(\"span\", {\"class\": \"v-align-middle social-details-social-counts__reactions-count\"})\\n    new_comments = engagement_container[0].find(\"li\", {\"class\": \"social-details-social-counts__comments social-details-social-counts__item\"})\\n\\n    \\n    post_dates.append(posted_date.text.strip())\\n    post_texts.append(new_box.text.strip())\\n\\n    try:\\n        post_likes.append(new_likes.text.strip())\\n    except:\\n        post_likes.append(0)\\n        pass\\n    \\n    try:\\n        post_comments.append(new_comments.text.strip())                           \\n    except:                                                           \\n        post_comments.append(0)\\n        pass\\n\\n\\n#Cleaning the dates\\ncleaned_dates = []\\nfor i in post_dates:\\n    d = str(i[0:3]).replace(\\'\\n\\n\\', \\'\\').replace(\\'â€¢\\',\\'\\').replace(\\' \\', \\'\\')\\n    cleaned_dates += [d]\\n\\n\\n\\n#Stripping non-numeric values\\ncomment_count = []\\nfor i in post_comments:\\n    s = str(i).replace(\\'Comment\\',\\'\\').replace(\\'s\\',\\'\\').replace(\\' \\',\\'\\')\\n    comment_count += [s]\\n\\n\\n#Constructing Pandas Dataframe\\ndata = {\\n    \"Date Posted\": cleaned_dates,\\n    \"Post Text\": post_texts,\\n    \"Post Likes\": post_likes,\\n    \"Post Comments\": comment_count\\n}\\n\\n\\ndf = pd.DataFrame(data)\\ndf\\n\\n\\n#Exporting csv to program folder\\ndf.to_csv(\"loreal_linkedin.csv\", encoding=\\'utf-8\\', index=False)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    }
  ]
}